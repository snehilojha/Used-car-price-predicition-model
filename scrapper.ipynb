{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "29dfe57e",
   "metadata": {},
   "outputs": [],
   "source": [
    "#pip install selenium beautifulsoup4 pandas webdriver-manager category_encoders scikit-learn numpy matplotlib catboost"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "07b37334",
   "metadata": {},
   "outputs": [],
   "source": [
    "import os\n",
    "import time\n",
    "import random\n",
    "import requests\n",
    "import json\n",
    "import pandas as pd\n",
    "import numpy as np\n",
    "from bs4 import BeautifulSoup\n",
    "from selenium import webdriver\n",
    "from selenium.webdriver.chrome.service import Service\n",
    "from selenium.webdriver.chrome.options import Options\n",
    "from webdriver_manager.chrome import ChromeDriverManager\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "ef46daa8",
   "metadata": {},
   "outputs": [],
   "source": [
    "# configuration\n",
    "\n",
    "BASE_URL = 'https://www.cardekho.com/used-cars+5-lakh-to-10-lakh+in+new-delhi'\n",
    "scroll_pause_time = 2\n",
    "max_scrolls = 10 # controls number of listings loaded\n",
    "output_file = 'data/cardekho_used_cars.csv'\n",
    "\n",
    "if os.path.exists(output_file):\n",
    "    existing_df = pd.read_csv(output_file)\n",
    "else:\n",
    "    existing_df = pd.DataFrame()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "6dea50d3",
   "metadata": {},
   "outputs": [],
   "source": [
    "# setting up driver\n",
    "\n",
    "def get_driver():\n",
    "    options = Options()\n",
    "    options.add_argument(\"--start-maximized\")\n",
    "    options.add_argument(\"--disable-blink-features=AutomationControlled\")\n",
    "    options.add_argument(\"--disable-notifications\")\n",
    "    options.add_argument(\"--disable-infobars\")\n",
    "    options.add_argument(\"--disable-extensions\")\n",
    "\n",
    "    return webdriver.Chrome(\n",
    "        service=Service(ChromeDriverManager().install()),\n",
    "        options=options\n",
    "    )"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "089e0b39",
   "metadata": {},
   "outputs": [],
   "source": [
    "# scroll page\n",
    "\n",
    "def scroll_page(driver):\n",
    "    last_height = driver.execute_script(\"return document.body.scrollHeight\")\n",
    "\n",
    "    for _ in range(max_scrolls):\n",
    "        driver.execute_script(\"window.scrollTo(0, document.body.scrollHeight);\")\n",
    "        time.sleep(random.uniform(2, 3))\n",
    "        new_height = driver.execute_script(\"return document.body.scrollHeight\")\n",
    "\n",
    "        if new_height == last_height:\n",
    "            break\n",
    "        last_height = new_height"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "e36d234e",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Collect car links\n",
    "\n",
    "def get_car_links(driver):\n",
    "    soup = BeautifulSoup(driver.page_source, \"html.parser\")\n",
    "    links = set()\n",
    "\n",
    "    for a in soup.select(\"a[href*='/used-car-details/']\"):\n",
    "        href = a.get(\"href\")\n",
    "        if href:\n",
    "            links.add(\"https://www.cardekho.com\" + href)\n",
    "\n",
    "    return list(links)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "ca34d230",
   "metadata": {},
   "outputs": [],
   "source": [
    "# scrape car details\n",
    "\n",
    "def scrape_car_page(driver, url):\n",
    "    driver.get(url)\n",
    "    time.sleep(random.uniform(2, 4))\n",
    "\n",
    "    soup = BeautifulSoup(driver.page_source, \"html.parser\")\n",
    "\n",
    "    # for debugging\n",
    "    with open('debug_page.html','w', encoding= 'utf-8') as f:\n",
    "        f.write(soup.prettify())\n",
    "    \n",
    "    details = {}\n",
    "\n",
    "    for item in soup.find_all('div', class_ = 'outer-card-container posR'):\n",
    "\n",
    "        labels = item.find_all('div', class_ = 'label')\n",
    "        values = item.find_all('span',class_ = 'value-text')\n",
    "\n",
    "        for label,value in zip(labels, values):\n",
    "            details[label.text.strip()] = value.text.strip()\n",
    "            # key = label.text.strip()\n",
    "            # val = value.text.strip()\n",
    "            # details[key] = val\n",
    "\n",
    "    def safe(tag, class_name):\n",
    "        el = soup.find(tag, class_ = class_name)\n",
    "        return el.text.strip() if el else None\n",
    "\n",
    "    data = {\n",
    "        \"url\": url,\n",
    "        \"title\": safe(\"div\",'vehicleName'),\n",
    "        \"price\": safe(\"div\",'vehiclePrice'),\n",
    "        \"registration_yr\": details.get('Registration Year'),\n",
    "        \"insurance\": details.get('Insurance'),\n",
    "        \"fuel_type\": details.get('Fuel Type'),\n",
    "        \"seats\": details.get('Seats'),\n",
    "        \"km_driven\": details.get('Kms Driven'),\n",
    "        \"ownership\": details.get('Ownership'),\n",
    "        \"engine_displacement\": details.get('Engine Displacement'),\n",
    "        \"transmission\": details.get('Transmission'),\n",
    "        \"manufacture_yr\": details.get('Year of Manufacture')\n",
    "    }\n",
    "\n",
    "    return data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "e2277fe3",
   "metadata": {},
   "outputs": [],
   "source": [
    "# main\n",
    "\n",
    "def main():\n",
    "    driver = get_driver()\n",
    "    driver.set_page_load_timeout(60)\n",
    "    time.sleep(5)\n",
    "    driver.get(BASE_URL)\n",
    "    time.sleep(5)\n",
    "\n",
    "    print(\"Scrolling page to load cars...\")\n",
    "    scroll_page(driver)\n",
    "\n",
    "    print(\"Collecting car links...\")\n",
    "    car_links = get_car_links(driver)\n",
    "    print(f\"Found {len(car_links)} listings\")\n",
    "\n",
    "    all_data = []\n",
    "\n",
    "    for i, link in enumerate(car_links[60:120], start=1):\n",
    "        print(f\"[{i}/{len(car_links)}] Scraping: {link}\")\n",
    "        try:\n",
    "            car_data = scrape_car_page(driver, link)\n",
    "            all_data.append(car_data)\n",
    "        except Exception as e:\n",
    "            print(f\"Failed on {link}: {e}\")\n",
    "        time.sleep(random.uniform(2, 4))\n",
    "\n",
    "    driver.quit()\n",
    "\n",
    "    new_df = pd.DataFrame(all_data)\n",
    "\n",
    "    if not existing_df.empty:\n",
    "        final_df = pd.concat([existing_df, new_df],ignore_index= True)\n",
    "    else:\n",
    "        final_df = new_df\n",
    "\n",
    "    final_df.to_csv(output_file, index=False)\n",
    "\n",
    "    print(f\"\\n Data saved to {output_file}\")\n",
    "    print(f\"Total records: {len(final_df)}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "037778f3",
   "metadata": {},
   "outputs": [],
   "source": [
    "if __name__ == \"__main__\":\n",
    "    main()"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": ".hpvenv (3.11.0)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "name": "python",
   "version": "3.11.0"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
